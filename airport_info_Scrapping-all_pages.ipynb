{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I- Phase de test sur une page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_airport = \"https://www.world-airport-codes.com/alphabetical/airport-code/b.html?page=1\"\n",
    "#url_airport = \"https://www.world-airport-codes.com/alphabetical/airport-code/a.html?page=6\"\n",
    "#url_airport = \"https://www.world-airport-codes.com/alphabetical/airport-code/h.html?page=3\"\n",
    "#url_airport = \"https://www.world-airport-codes.com/alphabetical/airport-code/n.html?page=4\"\n",
    "page2 = urlopen(url_airport)\n",
    "soup2 = bs(page2, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des infos des aéroports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_info = soup2.findAll('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = []\n",
    "country = []\n",
    "taille = []\n",
    "IATA = []\n",
    "ICAO = []\n",
    "\n",
    "for i in range(1,len(airport_info),6):\n",
    "    city.append(airport_info[i].text if airport_info[i].text == '' else airport_info[i].text.split(':')[1])\n",
    "    \n",
    "for i in range(2,len(airport_info),6):\n",
    "    country.append(airport_info[i].text.split(':')[1])\n",
    "    \n",
    "for i in range(0,len(airport_info),6):\n",
    "    taille.append(airport_info[i].text.replace(' ','').split(':')[1].split('\\n')[1])\n",
    "    \n",
    "for i in range(3,len(airport_info),6):\n",
    "    IATA.append(airport_info[i].text.split(':')[1].split(' ')[1])\n",
    "    \n",
    "for i in range(4,len(airport_info),6):\n",
    "    ICAO.append(airport_info[i].text if airport_info[i].text == '' else airport_info[i].text.split(':')[1].split(' ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in (city, country, taille, IATA, ICAO):\n",
    "    print(frame[0:5],'\\n',len(frame), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sur cette page il y a {} aéroports.\".format(len(city)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction du nom de l'aéroport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nom de l'aéroport vient après parce qu'on a besoin du nombre d'aéroports disponible sur la page à travers len(city)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_name = soup2.findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in range(49,len(city)+49):\n",
    "    name.append(airport_name[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(name)):\n",
    "    print(name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation d'un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_aeroport = pd.DataFrame(list(zip(name, city, country, taille, IATA, ICAO)), \n",
    "                       columns=['Aeroport', 'Ville', 'Pays', 'Taille', 'IATA', 'ICAO'])\n",
    "donnees_aeroport.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(donnees_aeroport.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut s'amuser à tester d'autres pages du site dans la première cellule mais le paramètre qui sert à extraire le nom de l'aéroport peut entrainer des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II- Généralisation de l'extraction sur toutes les pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_alphabet = list(string.ascii_lowercase) #pour générer la liste des lettres de l'alphabet #merci Soumaya\n",
    "list_alphabet = ['a','b','c'] #vous pouvez ajouter les lettres ou activer la ligne au dessus pour extraire toutes les lettres\n",
    "#cela prendra du temps\n",
    "city_all = []\n",
    "country_all = []\n",
    "taille_all = []\n",
    "IATA_all = []\n",
    "ICAO_all = []\n",
    "name_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in list_alphabet:\n",
    "    \n",
    "    url_airport_1 = f\"https://www.world-airport-codes.com/alphabetical/airport-code/{alpha}.html?page=1\"\n",
    "    page_1 = urlopen(url_airport_1)\n",
    "    soup_1 = bs(page_1, \"html.parser\")\n",
    "    airport_all = soup_1.findAll('a')\n",
    "    #extarction des infos de la pages 1. Nous avons besoin de connaitre le nombe de pages par lettre\n",
    "    #ex: les aéroports commençant par A sont sur 6 pages / les aéroports commençant par G sont sur 4 pages / etc...\n",
    "    info_page_1 = [] \n",
    "    for j in range(len(airport_all)):\n",
    "        info_page_1.append(airport_all[j].text)\n",
    "    \n",
    "    #nous remarquons le nombre de pages se trouvve dans la liste info_page_1 de la première page avant l'élément \"›\"\n",
    "    info_utile = info_page_1.index(\"›\")\n",
    "    nb_pages = int(info_page_1[info_utile-1])\n",
    "    \n",
    "        \n",
    "    for p in range(1, nb_pages+1):\n",
    "        if p == 1:\n",
    "            debut_scrap = info_utile+1\n",
    "        elif p == nb_pages:\n",
    "            debut_scrap = info_utile+1\n",
    "        else :\n",
    "            debut_scrap = info_utile+2\n",
    "            \n",
    "        \n",
    "        url_airport_codes = f\"https://www.world-airport-codes.com/alphabetical/airport-code/{alpha}.html?page={p}\"\n",
    "        page_i = urlopen(url_airport_codes)\n",
    "        soup_i = bs(page_i, \"html.parser\")\n",
    "        \n",
    "        city = []\n",
    "        country = []\n",
    "        taille = []\n",
    "        IATA = []\n",
    "        ICAO = []\n",
    "        name = []\n",
    "        \n",
    "            #extraction des infos des aéroports\n",
    "        airport_info_all = soup_i.findAll('td')\n",
    "        \n",
    "        for j in range(1,len(airport_info_all),6):\n",
    "            city.append(airport_info_all[j].text if airport_info_all[j].text == '' else airport_info_all[j].text.split(':')[1])\n",
    "    \n",
    "        for k in range(2,len(airport_info_all),6):\n",
    "            country.append(airport_info_all[k].text if airport_info_all[k].text =='' else  airport_info_all[k].text.split(':')[1])\n",
    "    \n",
    "        for l in range(0,len(airport_info_all),6):\n",
    "            taille.append(airport_info_all[l].text if airport_info_all[l].text == '' else airport_info_all[l].text.replace(' ','').split(':')[1].split('\\n')[1])\n",
    "    \n",
    "        for m in range(3,len(airport_info_all),6):\n",
    "            IATA.append(airport_info_all[m].text if airport_info_all[m].text =='' else airport_info_all[m].text.split(':')[1].split(' ')[1])\n",
    "    \n",
    "        for n in range(4,len(airport_info_all),6):\n",
    "            ICAO.append(airport_info_all[n].text if airport_info_all[n].text == '' else airport_info_all[n].text.split(':')[1].split(' ')[1])\n",
    "\n",
    "        #extraction des noms des aéroports\n",
    "        airport_name_all = soup_i.findAll('a')\n",
    "        \n",
    "        for i in range(debut_scrap,(len(city)+debut_scrap)):\n",
    "            name.append(airport_name_all[i].text if  airport_name_all[i].text == '' else airport_name_all[i].text)\n",
    "            \n",
    "        city_all.extend(city)\n",
    "        country_all.extend(country)\n",
    "        taille_all.extend(taille)\n",
    "        IATA_all.extend(IATA)\n",
    "        ICAO_all.extend(ICAO)\n",
    "        name_all.extend(name)\n",
    "            \n",
    "        print(f'Scrapping de la page {alpha}-{p} réussie')\n",
    "        #pour être sûr que la page a été "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_aeroport_all = pd.DataFrame(list(zip(name_all, city_all, country_all, taille_all, IATA_all, ICAO_all)), \n",
    "                       columns=['Aeroport', 'Ville', 'Pays', 'Taille', 'IATA', 'ICAO'])\n",
    "donnees_aeroport_all.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
